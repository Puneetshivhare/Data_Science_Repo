# **Credit Card Fraud Detection**  

This project aims to detect fraudulent credit card transactions using machine learning techniques. Given the highly imbalanced nature of the dataset, we explore methods like **SMOTE (Synthetic Minority Oversampling Technique)** to handle class imbalance effectively.

---

## **ğŸ” Project Overview**  

### Problem Statement:  
Predict fraudulent transactions to minimize financial losses for banks and customers.  

### Key Challenges:  
- **Imbalanced Dataset**: Only 0.17% of transactions are fraudulent.  
- **Feature Scaling**: Ensure numerical stability in the model.  
- **Metric Selection**: Use ROC-AUC for performance evaluation due to imbalanced data.

---

## **ğŸ“Š Tools & Technologies**  
- **Python**: Data preprocessing and model development.  
- **scikit-learn**: For implementing classification models and SMOTE.  
- **matplotlib & seaborn**: Data visualization.  
- **imbalanced-learn**: Handling imbalanced datasets.

---

## **ğŸ“‚ Project Structure**  

```plaintext
fraud-detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ creditcard.csv    # Raw dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing.ipynb    # Data preparation and EDA
â”‚   â”œâ”€â”€ smote_model.ipynb      # Model with SMOTE
â”‚   â”œâ”€â”€ normal_model.ipynb     # Model without oversampling
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_regression.pkl  # Trained logistic regression model
â”‚   â”œâ”€â”€ xgboost_model.pkl        # Trained XGBoost model
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```
## **ğŸš€ Approach**
**Data Preprocessing**

1. Removed the Time column as it showed no specific pattern.
2. Scaled the Amount column using StandardScaler.
3. Class Imbalance Handling

## **SMOTE**: Generated synthetic data to balance classes.
Built separate models for balanced (SMOTE) and imbalanced data.
## **Model Building**

Explored logistic regression and XGBoost.
Evaluated models using ROC-AUC and F1-Score.

## **ğŸ“Š Key Results**
Model	ROC-AUC Score (Train)	ROC-AUC Score (Test)	F1-Score
Logistic Regression	0.97	0.96	0.77
SMOTE + Logistic	0.99	0.98	0.81
## **ğŸ“ Insights**
SMOTE significantly improves sensitivity and F1-Score for fraudulent transactions.
XGBoost achieves higher precision but is computationally expensive compared to logistic regression.
